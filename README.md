# VESSL examples
This repository contains examples of how to use [VESSL](https://www.vessl.ai/). If you want to learn more about VESSL, please follow the [quick start documentation](https://docs.vessl.ai/guides/get-started/quickstart).

Each directory contains the examples of corresponding features, such as [VESSL Run](https://docs.vessl.ai/guides/run/overview), [VESSL Service](https://docs.vessl.ai/guides/serve/overview), and [VESSL Pipeline](https://docs.vessl.ai/guides/pipeline/overview). If you want to dive into them more, please refer to the docs.

## Try out VESSL quickstarts
- [Run RAG chatbot using LangChain with VESSL Run](runs/rag-chatbot/)
- [Fine-tune Meta Llama 3.1 using VESSL Run](runs/finetune-llms/)
- [Run FLUX.1 schnell model](runs/flux.1-schnell)
- [Deploy Llama 3 service with vLLM on VESSL Service](services/service-llama-3)
