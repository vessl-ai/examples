name: rag-chatbot
description: RAG chatbot
tags:
  - RAG
  - LLM
resources:
  cluster: vessl-gcp-oregon
  preset: gpu-l4-small-spot
image: quay.io/vessl-ai/torch:2.1.0-cuda12.2-r3
import:
  /code/:
    git:
      url: github.com/vessl-ai/examples.git
run:
  - command: |  # Install some dependencies for LLM acceleration those have conflicts with common libraries
      pip install vllm==0.4.1 autoawq==0.2.5
      pip uninstall -y transformer-engine flash-attn
      pip install flash-attn==2.5.8
    workdir: /code
  - command: |
      python -m vllm.entrypoints.openai.api_server --model $MODEL_NAME --dtype auto --gpu-memory-utilization 0.8 &
    workdir: /code
  - command: |
      pip install -r requirements.txt
    workdir: /code/rag-chatbot
  - command: |
      python app.py --llm-host http://localhost:8000/v1
    workdir: /code/rag-chatbot
ports:
  - name: gradio
    type: http
    port: 7860
  - name: vllm
    type: http
    port: 8000
env:
  MODEL_NAME: casperhansen/llama-3-8b-instruct-awq
