name: raw-llm-chain
import:
  /code/:
    git:
      url: github.com/vessl-ai/examples.git
      ref: main
  /data/: vessl-dataset://{organization}/{claims-dataset-name}
export:
  /output/: vessl-dataset://{organization}/{rag-results-dataset-name}
resources:
  cluster: vessl-gcp-oregon
  preset: cpu-small-spot
image: quay.io/vessl-ai/python:3.10-r18
run:
  - command: pip install -r requirements.txt
    workdir: /code/rag-evaluation
  - command: |-
      python 2.1-raw-llm-chain.py \
        --llm-endpoint ${LLM_ENDPOINT} \
        --llm-model ${LLM_MODEL}
    workdir: /code/rag-evaluation
env:
  LLM_ENDPOINT: https://api.openai.com  # any OpenAI-compatible LLM endpoint
  LLM_MODEL: gpt-4o
  OPENAI_API_KEY: na  # update this if you are using OpenAI API
