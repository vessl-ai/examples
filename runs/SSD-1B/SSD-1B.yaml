name: inference_SSD-1B
resources:
  cluster: vessl-gcp-oregon
  preset: gpu-l4-small-spot
image: quay.io/vessl-ai/torch:2.3.1-cuda12.1-r5
import:
  /dataset/: vessl-model://vessl-ai/SSD-1B/1
  /root/examples/: git://github.com/vessl-ai/examples.git
run:
  - command: |-
      pip install --upgrade pip
      pip install -r requirements.txt
      pip install diffusers==0.27.2
      mkdir /data
      cd /dataset
      mv SSD-1B.tar.gz /data
      cd /data/
      tar -xvf SSD-1B.tar.gz
      cd /root/examples/SSD-1B
      python SSD-1B_inference.py
      streamlit run SSD-1B_streamlit.py --server.port=80
    workdir: /root/examples/SSD-1B
interactive:
  max_runtime: 24h
  jupyter:
    idle_timeout: 120m
ports:
  - name: streamlit
    type: http
    port: 80
