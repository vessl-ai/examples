{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "747e0e8d",
      "metadata": {
        "id": "747e0e8d"
      },
      "source": [
        "# BentoML Scikit-learn Tutorial\n",
        "\n",
        "\n",
        "This is a sample project demonstrating basic usage of [BentoML](https://github.com/bentoml) with\n",
        "Scikit-learn.\n",
        "\n",
        "In this project, we will train a classifier model using Scikit-learn and the Iris dataset, build\n",
        "a prediction service for serving the trained model via an HTTP server, and containerize the \n",
        "model server as a docker image for production deployment.\n",
        "\n",
        "\n",
        "Link to source code: https://github.com/bentoml/BentoML/tree/main/examples/quickstart\n",
        "\n",
        "### Install Dependencies\n",
        "\n",
        "Install required python packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "daa3cbef",
      "metadata": {
        "id": "daa3cbef",
        "outputId": "553113cd-eedf-49d4-8572-5767c6d83a5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 1)) (1.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 2)) (1.3.5)\n",
            "Collecting bentoml>=1.0.0\n",
            "  Downloading bentoml-1.0.14-py3-none-any.whl (946 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m946.5/946.5 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 1)) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 2)) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 2)) (2.8.2)\n",
            "Collecting pip-requirements-parser>=31.2.0\n",
            "  Downloading pip_requirements_parser-32.0.1-py3-none-any.whl (35 kB)\n",
            "Collecting rich>=11.2.0\n",
            "  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cattrs>=22.1.0\n",
            "  Downloading cattrs-22.2.0-py3-none-any.whl (35 kB)\n",
            "Collecting simple-di>=0.1.4\n",
            "  Downloading simple_di-0.1.5-py3-none-any.whl (9.8 kB)\n",
            "Collecting pathspec\n",
            "  Downloading pathspec-0.11.0-py3-none-any.whl (29 kB)\n",
            "Collecting opentelemetry-instrumentation-aiohttp-client==0.35b0\n",
            "  Downloading opentelemetry_instrumentation_aiohttp_client-0.35b0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (2.25.1)\n",
            "Collecting opentelemetry-api==1.14.0\n",
            "  Downloading opentelemetry_api-1.14.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynvml<12\n",
            "  Downloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 KB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-semantic-conventions==0.35b0\n",
            "  Downloading opentelemetry_semantic_conventions-0.35b0-py3-none-any.whl (26 kB)\n",
            "Collecting Jinja2>=3.0.1\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting circus!=0.17.2,>=0.17.0\n",
            "  Downloading circus-0.18.0-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.6/200.6 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette\n",
            "  Downloading starlette-0.24.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn\n",
            "  Downloading uvicorn-0.20.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prometheus-client>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (0.16.0)\n",
            "Requirement already satisfied: PyYAML>=5.0 in /usr/local/lib/python3.8/dist-packages (from bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (6.0)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.35b0\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.35b0-py3-none-any.whl (13 kB)\n",
            "Collecting opentelemetry-instrumentation==0.35b0\n",
            "  Downloading opentelemetry_instrumentation-0.35b0-py3-none-any.whl (24 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.14.0\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.14.0-py3-none-any.whl (21 kB)\n",
            "Collecting opentelemetry-sdk==1.14.0\n",
            "  Downloading opentelemetry_sdk-1.14.0-py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.5/94.5 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-util-http==0.35b0\n",
            "  Downloading opentelemetry_util_http-0.35b0-py3-none-any.whl (6.7 kB)\n",
            "Requirement already satisfied: attrs>=21.1.0 in /usr/local/lib/python3.8/dist-packages (from bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (22.2.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (3.8.3)\n",
            "Requirement already satisfied: pip-tools>=6.6.2 in /usr/local/lib/python3.8/dist-packages (from bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (6.6.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (5.4.8)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (2.2.1)\n",
            "Collecting click-option-group\n",
            "  Downloading click_option_group-0.5.5-py3-none-any.whl (12 kB)\n",
            "Collecting python-json-logger\n",
            "  Downloading python_json_logger-2.0.4-py3-none-any.whl (7.8 kB)\n",
            "Collecting watchfiles>=0.15.0\n",
            "  Downloading watchfiles-0.18.1-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.8/dist-packages (from bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (23.0)\n",
            "Collecting deepmerge\n",
            "  Downloading deepmerge-1.1.0-py3-none-any.whl (8.5 kB)\n",
            "Collecting schema\n",
            "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
            "Collecting fs\n",
            "  Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.8/dist-packages (from opentelemetry-api==1.14.0->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (57.4.0)\n",
            "Collecting deprecated>=1.2.6\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting opentelemetry-proto==1.14.0\n",
            "  Downloading opentelemetry_proto-1.14.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff<3.0.0,>=1.10.0\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.8/dist-packages (from opentelemetry-exporter-otlp-proto-http==1.14.0->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (1.58.0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from opentelemetry-instrumentation==0.35b0->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (1.14.1)\n",
            "Collecting asgiref~=3.0\n",
            "  Downloading asgiref-3.6.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.8/dist-packages (from opentelemetry-sdk==1.14.0->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (4.4.0)\n",
            "Requirement already satisfied: protobuf~=3.13 in /usr/local/lib/python3.8/dist-packages (from opentelemetry-proto==1.14.0->opentelemetry-exporter-otlp-proto-http==1.14.0->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (3.19.6)\n",
            "Collecting exceptiongroup\n",
            "  Downloading exceptiongroup-1.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyzmq>=17.0 in /usr/local/lib/python3.8/dist-packages (from circus!=0.17.2,>=0.17.0->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (23.2.1)\n",
            "Requirement already satisfied: tornado>=5.0.2 in /usr/local/lib/python3.8/dist-packages (from circus!=0.17.2,>=0.17.0->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (6.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=3.0.1->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (2.0.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from pip-requirements-parser>=31.2.0->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (3.0.9)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from pip-tools>=6.6.2->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (0.38.4)\n",
            "Requirement already satisfied: pep517 in /usr/local/lib/python3.8/dist-packages (from pip-tools>=6.6.2->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (0.13.0)\n",
            "Requirement already satisfied: pip>=21.2 in /usr/local/lib/python3.8/dist-packages (from pip-tools>=6.6.2->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (22.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (4.0.0)\n",
            "Collecting pygments<3.0.0,>=2.14.0\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown-it-py<3.0.0,>=2.1.0\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anyio>=3.0.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (2.1.1)\n",
            "Requirement already satisfied: appdirs~=1.4.3 in /usr/local/lib/python3.8/dist-packages (from fs->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (1.4.4)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.8/dist-packages (from schema->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (0.5.5)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from pep517->pip-tools>=6.6.2->bentoml>=1.0.0->-r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt (line 3)) (2.0.1)\n",
            "Building wheels for collected packages: python-multipart\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=57b16d68c56055265fc432b9f1e63930b6a95cb8eeeeec5666768957778eae2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/fc/1c/cf980e6413d3ee8e70cd8f39e2366b0f487e3e221aeb452eb0\n",
            "Successfully built python-multipart\n",
            "Installing collected packages: deepmerge, sniffio, simple-di, schema, python-multipart, python-json-logger, pynvml, pygments, pip-requirements-parser, pathspec, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, mdurl, Jinja2, h11, fs, exceptiongroup, deprecated, click-option-group, circus, backoff, asgiref, uvicorn, opentelemetry-api, markdown-it-py, cattrs, anyio, watchfiles, starlette, rich, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-aiohttp-client, opentelemetry-exporter-otlp-proto-http, bentoml\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "notebook 5.7.16 requires jinja2<=3.0.0, but you have jinja2 3.1.2 which is incompatible.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Jinja2-3.1.2 anyio-3.6.2 asgiref-3.6.0 backoff-2.2.1 bentoml-1.0.14 cattrs-22.2.0 circus-0.18.0 click-option-group-0.5.5 deepmerge-1.1.0 deprecated-1.2.13 exceptiongroup-1.1.0 fs-2.4.16 h11-0.14.0 markdown-it-py-2.1.0 mdurl-0.1.2 opentelemetry-api-1.14.0 opentelemetry-exporter-otlp-proto-http-1.14.0 opentelemetry-instrumentation-0.35b0 opentelemetry-instrumentation-aiohttp-client-0.35b0 opentelemetry-instrumentation-asgi-0.35b0 opentelemetry-proto-1.14.0 opentelemetry-sdk-1.14.0 opentelemetry-semantic-conventions-0.35b0 opentelemetry-util-http-0.35b0 pathspec-0.11.0 pip-requirements-parser-32.0.1 pygments-2.14.0 pynvml-11.4.1 python-json-logger-2.0.4 python-multipart-0.0.5 rich-13.3.1 schema-0.7.5 simple-di-0.1.5 sniffio-1.3.0 starlette-0.24.0 uvicorn-0.20.0 watchfiles-0.18.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r https://raw.githubusercontent.com/bentoml/BentoML/main/examples/quickstart/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b66e31f7",
      "metadata": {
        "id": "b66e31f7"
      },
      "source": [
        "##  Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "eb526488",
      "metadata": {
        "id": "eb526488",
        "outputId": "3f419c8d-6eb1-4bec-ff20-5409b3ad8465",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm, datasets\n",
        "\n",
        "# Load training data\n",
        "iris = datasets.load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Model Training\n",
        "clf = svm.SVC()\n",
        "clf.fit(X, y)\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c114c75",
      "metadata": {
        "id": "3c114c75"
      },
      "source": [
        "Save the `clf` model instance to BentoML local model store:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e94ed449",
      "metadata": {
        "id": "e94ed449",
        "outputId": "21c85d84-0142-43e3-913d-e5f124d6b48a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(tag=\"iris_clf:n4m6w6vhr2lbmasc\", path=\"/root/bentoml/models/iris_clf/n4m6w6vhr2lbmasc/\")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import bentoml\n",
        "\n",
        "bentoml.sklearn.save_model(\"iris_clf\", clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d613e57e",
      "metadata": {
        "id": "d613e57e"
      },
      "source": [
        "Models saved can be accessed via `bentoml models` CLI command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7d771f04",
      "metadata": {
        "id": "7d771f04",
        "outputId": "5b5e132a-e79b-4b5f-f9a5-db3d679c71d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[91;40mname\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40miris_clf\u001b[0m\u001b[40m                                                                  \u001b[0m\n",
            "\u001b[91;40mversion\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mn4m6w6vhr2lbmasc\u001b[0m\u001b[40m                                                       \u001b[0m\n",
            "\u001b[91;40mmodule\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mbentoml.sklearn\u001b[0m\u001b[40m                                                         \u001b[0m\n",
            "\u001b[91;40mlabels\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m{\u001b[0m\u001b[40m}\u001b[0m\u001b[40m                                                                      \u001b[0m\n",
            "\u001b[91;40moptions\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m{\u001b[0m\u001b[40m}\u001b[0m\u001b[40m                                                                     \u001b[0m\n",
            "\u001b[91;40mmetadata\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m{\u001b[0m\u001b[40m}\u001b[0m\u001b[40m                                                                    \u001b[0m\n",
            "\u001b[91;40mcontext\u001b[0m\u001b[97;40m:\u001b[0m\u001b[40m                                                                        \u001b[0m\n",
            "\u001b[97;40m  \u001b[0m\u001b[91;40mframework_name\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40msklearn\u001b[0m\u001b[40m                                                       \u001b[0m\n",
            "\u001b[97;40m  \u001b[0m\u001b[91;40mframework_versions\u001b[0m\u001b[97;40m:\u001b[0m\u001b[40m                                                           \u001b[0m\n",
            "\u001b[97;40m    \u001b[0m\u001b[91;40mscikit-learn\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m1.0.2\u001b[0m\u001b[40m                                                         \u001b[0m\n",
            "\u001b[97;40m  \u001b[0m\u001b[91;40mbentoml_version\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m1.0.13\u001b[0m\u001b[40m                                                       \u001b[0m\n",
            "\u001b[97;40m  \u001b[0m\u001b[91;40mpython_version\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m3.8.10\u001b[0m\u001b[40m                                                        \u001b[0m\n",
            "\u001b[91;40msignatures\u001b[0m\u001b[97;40m:\u001b[0m\u001b[40m                                                                     \u001b[0m\n",
            "\u001b[97;40m  \u001b[0m\u001b[91;40mpredict\u001b[0m\u001b[97;40m:\u001b[0m\u001b[40m                                                                      \u001b[0m\n",
            "\u001b[97;40m    \u001b[0m\u001b[91;40mbatchable\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mfalse\u001b[0m\u001b[40m                                                            \u001b[0m\n",
            "\u001b[91;40mapi_version\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mv1\u001b[0m\u001b[40m                                                                 \u001b[0m\n",
            "\u001b[91;40mcreation_time\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[93;40m'\u001b[0m\u001b[93;40m2023-02-08T08:56:10.952718+00:00\u001b[0m\u001b[93;40m'\u001b[0m\u001b[40m                               \u001b[0m\n",
            "\u001b[40m                                                                                \u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!bentoml models get iris_clf:latest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5a876780",
      "metadata": {
        "id": "5a876780",
        "outputId": "ae3cb5e3-03b1-432f-a08b-68b5a4c8b9ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m \u001b[0m\u001b[1mTag                      \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mModule         \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mSize    \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCreation Time      \u001b[0m\u001b[1m \u001b[0m\n",
            " iris_clf:n4m6w6vhr2lbmasc  bentoml.sklearn  5.83 KiB  2023-02-08 08:56:10 \n"
          ]
        }
      ],
      "source": [
        "!bentoml models list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "672721c4",
      "metadata": {
        "id": "672721c4"
      },
      "source": [
        "To verify that the saved model can be loaded correctly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "28ac794b",
      "metadata": {
        "id": "28ac794b",
        "outputId": "457305c8-342c-42f0-91d9-65c63c8c6a6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "loaded_model = bentoml.sklearn.load_model(\"iris_clf:latest\")\n",
        "\n",
        "loaded_model.predict([[5.9, 3.0, 5.1, 1.8]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fd3bf97",
      "metadata": {
        "id": "8fd3bf97"
      },
      "source": [
        "In BentoML, the recommended way of running ML model inference in serving is via Runner, which \n",
        "gives BentoML more flexibility in terms of how to schedule the inference computation, how to \n",
        "batch inference requests and take advantage of hardware resources available. Saved models can\n",
        "be loaded as a Runner instance as shown below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "83205567",
      "metadata": {
        "id": "83205567",
        "outputId": "1ba056de-ba19-4ea3-e535-b616691e461c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:bentoml._internal.runner.runner:'Runner.init_local' is for debugging and testing only. Make sure to remove it before deploying to production.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Create a Runner instance:\n",
        "iris_clf_runner = bentoml.sklearn.get(\"iris_clf:latest\").to_runner()\n",
        "\n",
        "# Runner#init_local initializes the model in current process, this is meant for development and testing only:\n",
        "iris_clf_runner.init_local()\n",
        "\n",
        "# This should yield the same result as the loaded model:\n",
        "iris_clf_runner.predict.run([[5.9, 3.0, 5.1, 1.8]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fa68254",
      "metadata": {
        "id": "3fa68254"
      },
      "source": [
        "## Serving the model\n",
        "\n",
        "A simple BentoML Service that serves the model saved above looks like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "127aa3fd",
      "metadata": {
        "id": "127aa3fd",
        "outputId": "027e81b7-1813-4a31-df6e-c2fcdc24a45b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing service.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile service.py\n",
        "import numpy as np\n",
        "import bentoml\n",
        "from bentoml.io import NumpyNdarray\n",
        "\n",
        "iris_clf_runner = bentoml.sklearn.get(\"iris_clf:latest\").to_runner()\n",
        "\n",
        "svc = bentoml.Service(\"iris_classifier\", runners=[iris_clf_runner])\n",
        "\n",
        "@svc.api(input=NumpyNdarray(), output=NumpyNdarray())\n",
        "def classify(input_series: np.ndarray) -> np.ndarray:\n",
        "    return iris_clf_runner.predict.run(input_series)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "203beeed",
      "metadata": {
        "id": "203beeed"
      },
      "source": [
        "Note: using `%%writefile` here because `bentoml.Service` definition must be created in its own `.py` file\n",
        "\n",
        "Start a dev model server to test out the service defined above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7523b58f",
      "metadata": {
        "id": "7523b58f",
        "outputId": "773be5fa-d116-45ea-dd15-7b8b2aad2e44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-08T09:01:14+0000 [INFO] [cli] Prometheus metrics for HTTP BentoServer from \"service.py:svc\" can be accessed at http://localhost:3000/metrics.\n",
            "2023-02-08T09:01:14+0000 [INFO] [cli] Starting development HTTP BentoServer from \"service.py:svc\" listening on http://0.0.0.0:3000 (Press CTRL+C to quit)\n",
            "2023-02-08 09:01:15 circus[1901] [INFO] Loading the plugin...\n",
            "2023-02-08 09:01:15 circus[1901] [INFO] Endpoint: 'tcp://127.0.0.1:50687'\n",
            "2023-02-08 09:01:15 circus[1901] [INFO] Pub/sub: 'tcp://127.0.0.1:38539'\n",
            "2023-02-08T09:01:15+0000 [INFO] [observer] Watching directories: ['/content', '/root/bentoml/models']\n",
            "2023-02-08T09:14:23+0000 [ERROR] [cli] Exception in callback <bound method Arbiter.manage_watchers of <circus.arbiter.Arbiter object at 0x7f7dc3b37bb0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/circus/util.py\", line 1126, in _run\n",
            "    val = self.callback()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/circus/util.py\", line 1038, in wrapper\n",
            "    raise ConflictError(\"arbiter is already running %s command\"\n",
            "circus.exc.ConflictError: arbiter is already running arbiter_stop command\n"
          ]
        }
      ],
      "source": [
        "!bentoml serve service.py:svc --reload"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3974e4ce",
      "metadata": {
        "id": "3974e4ce"
      },
      "source": [
        "\n",
        "Open your web browser at http://127.0.0.1:3000 to view the Bento UI for sending test requests.\n",
        "\n",
        "You may also send request with `curl` command or any HTTP client, e.g.:\n",
        "\n",
        "```bash\n",
        "curl -X POST -H \"content-type: application/json\" --data \"[[5.9, 3, 5.1, 1.8]]\" http://127.0.0.1:3000/classify\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f1a8bcc",
      "metadata": {
        "id": "4f1a8bcc"
      },
      "source": [
        "### Build Bento for deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6192cd5",
      "metadata": {
        "id": "d6192cd5"
      },
      "source": [
        "Bento is the distribution format in BentoML which captures all the source code, model files, config\n",
        "files and dependency specifications required for running the service for production deployment. Think \n",
        "of it as Docker/Container designed for machine learning models.\n",
        "\n",
        "To begin with building Bento, create a `bentofile.yaml` under your project directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6458e417",
      "metadata": {
        "id": "6458e417",
        "outputId": "1df498ef-ed53-407e-8e5e-0c212534f278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing bentofile.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile bentofile.yaml\n",
        "service: \"service.py:svc\"\n",
        "labels:\n",
        "  owner: bentoml-team\n",
        "  project: gallery\n",
        "include:\n",
        "- \"*.py\"\n",
        "python:\n",
        "  packages:\n",
        "    - scikit-learn\n",
        "    - pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cat bentofile.yaml"
      ],
      "metadata": {
        "id": "g2wQwZAtTiRD",
        "outputId": "7881af2c-6ab8-46e5-b911-4b9dc48aa87d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "g2wQwZAtTiRD",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "service: \"service.py:svc\"\n",
            "labels:\n",
            "  owner: bentoml-team\n",
            "  project: gallery\n",
            "include:\n",
            "- \"*.py\"\n",
            "python:\n",
            "  packages:\n",
            "    - scikit-learn\n",
            "    - pandas\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47505e3c",
      "metadata": {
        "id": "47505e3c"
      },
      "source": [
        "Next, run `bentoml build` from current directory to start the Bento build:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b7cab8b2",
      "metadata": {
        "id": "b7cab8b2",
        "outputId": "14b67ed2-0430-4f79-d9e5-4dd487ee7044",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building BentoML service \"iris_classifier:lha554fhskb5wasc\" from build context \"/content\".\n",
            "Packing model \"iris_clf:n4m6w6vhr2lbmasc\"\n",
            "Locking PyPI package versions.\n",
            "\n",
            "██████╗░███████╗███╗░░██╗████████╗░█████╗░███╗░░░███╗██╗░░░░░\n",
            "██╔══██╗██╔════╝████╗░██║╚══██╔══╝██╔══██╗████╗░████║██║░░░░░\n",
            "██████╦╝█████╗░░██╔██╗██║░░░██║░░░██║░░██║██╔████╔██║██║░░░░░\n",
            "██╔══██╗██╔══╝░░██║╚████║░░░██║░░░██║░░██║██║╚██╔╝██║██║░░░░░\n",
            "██████╦╝███████╗██║░╚███║░░░██║░░░╚█████╔╝██║░╚═╝░██║███████╗\n",
            "╚═════╝░╚══════╝╚═╝░░╚══╝░░░╚═╝░░░░╚════╝░╚═╝░░░░░╚═╝╚══════╝\n",
            "\n",
            "Successfully built Bento(tag=\"iris_classifier:lha554fhskb5wasc\").\n"
          ]
        }
      ],
      "source": [
        "!bentoml build"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c159551",
      "metadata": {
        "id": "4c159551"
      },
      "source": [
        "A new Bento is now built and saved to local Bento store. You can view and manage it via \n",
        "`bentoml list`,`bentoml get` and `bentoml delete` CLI command."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81ed8b84",
      "metadata": {
        "id": "81ed8b84"
      },
      "source": [
        "## Containerize and Deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c215454",
      "metadata": {
        "id": "8c215454"
      },
      "source": [
        "Bento is designed to be deployed to run efficiently in a variety of different environments.\n",
        "And there are lots of deployment options and tools as part of the BentoML eco-system, such as \n",
        "[Yatai](https://github.com/bentoml/Yatai) and [bentoctl](https://github.com/bentoml/bentoctl) for\n",
        "direct deployment to cloud platforms.\n",
        "\n",
        "In this guide, we will show you the most basic way of deploying a Bento, which is converting a Bento\n",
        "into a Docker image containing the HTTP model server.\n",
        "\n",
        "Make sure you have docker installed and docker deamon running, and run the following commnand:\n",
        "\n",
        "```bash\n",
        "bentoml containerize iris_classifier:latest\n",
        "```\n",
        "\n",
        "This will build a new docker image with all source code, model files and dependencies in place,\n",
        "and ready for production deployment. To start a container with this docker image locally, run:\n",
        "\n",
        "```bash\n",
        "docker run -p 3000:3000 iris_classifier:invwzzsw7li6zckb2ie5eubhd \n",
        "```\n",
        "\n",
        "## What's Next?\n",
        "\n",
        "- 👉 [Pop into our Slack community!](https://l.linklyhq.com/l/ktO8) We're happy to help with any issue you face or even just to meet you and hear what you're working on.\n",
        "\n",
        "- Dive deeper into the [Core Concepts](https://docs.bentoml.org/en/latest/concepts/index.html) in BentoML\n",
        "- Learn how to use BentoML with other ML Frameworks at [Frameworks Guide](https://docs.bentoml.org/en/latest/frameworks/index.html) or check out other [gallery projects](https://github.com/bentoml/BentoML/tree/main/examples)\n",
        "- Learn more about model deployment options for Bento:\n",
        "  - [🦄️ Yatai](https://github.com/bentoml/Yatai): Model Deployment at scale on Kubernetes\n",
        "  - [🚀 bentoctl](https://github.com/bentoml/bentoctl): Fast model deployment on any cloud platform\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}