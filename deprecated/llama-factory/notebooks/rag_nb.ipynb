{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from peft import PeftModel\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig, MixtralForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS_DIR = \"/vessl-docs\"\n",
    "\n",
    "LORA_PATH = \"/lora/checkpoint-100\"\n",
    "QLORA_PATH = \"/qlora/checkpoint-100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
    "model = MixtralForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, padding_side=\"right\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(DOCS_DIR, recursive=True).load_data()\n",
    "index = VectorStoreIndex.from_documents(documents, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How can I create a new model via web?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_llm = HuggingFaceLLM(\n",
    "    context_window=4096,\n",
    "    max_new_tokens=512,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "query_engine = index.as_query_engine(llm=base_llm)\n",
    "\n",
    "response = query_engine.query(question)\n",
    "print(\"==BASE MODEL==\")\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model = PeftModel.from_pretrained(model, LORA_PATH)\n",
    "lora_llm = HuggingFaceLLM(\n",
    "    context_window=4096,\n",
    "    max_new_tokens=512,\n",
    "    model=lora_model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "query_engine = index.as_query_engine(llm=lora_llm)\n",
    "\n",
    "response = query_engine.query(question)\n",
    "print(\"==LORA MODEL==\")\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qlora_model = PeftModel.from_pretrained(model, QLORA_PATH)\n",
    "qlora_llm = HuggingFaceLLM(\n",
    "    context_window=4096,\n",
    "    max_new_tokens=512,\n",
    "    model=qlora_model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "query_engine = index.as_query_engine(llm=base_llm)\n",
    "\n",
    "response = query_engine.query(question)\n",
    "print(\"==QLORA MODEL==\")\n",
    "print(response.response)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
