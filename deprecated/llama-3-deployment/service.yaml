name: llama-3-textgen
message: deploy
image: quay.io/vessl-ai/torch:2.3.1-cuda12.1-r5
resources:
  cluster: vessl-gcp-oregon
  preset: gpu-l4-small-spot
import:
  /code/:
    git:
      url: github.com/vessl-ai/examples.git
run:
- command: |
    pip install -r requirements.txt
    python -m api --model $MODEL_NAME --max-model-len 4096 --disable-log-requests
  workdir: /code/llama-3-deployment
env:
  MODEL_NAME: casperhansen/llama-3-8b-instruct-awq
ports:
- port: 8000
service:
  autoscaling:
    max: 2
    metric: cpu
    min: 1
    target: 50
  expose: 8000
